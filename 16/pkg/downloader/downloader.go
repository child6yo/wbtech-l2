package downloader

import (
	"fmt"
	"io"
	"net/http"
	"net/url"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"golang.org/x/net/html"
)

// Downloader â€” ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¾Ð¹.
type Downloader struct {
	userAgent string
	outputDir string
	maxDepth  int
	visited   map[string]bool
	mu        sync.RWMutex
	client    *http.Client
}

// NewDownloader â€” ÑÐ¾Ð·Ð´Ð°ÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð·Ð°Ð³Ñ€ÑƒÐ·Ñ‡Ð¸ÐºÐ°.
func NewDownloader(userAgent, outputDir string, maxDepth int) *Downloader {
	return &Downloader{
		userAgent: userAgent,
		outputDir: outputDir,
		maxDepth:  maxDepth,
		visited:   make(map[string]bool),
		client:    &http.Client{Timeout: 30 * time.Second},
	}
}

// Download â€” Ñ‚Ð¾Ñ‡ÐºÐ° Ð²Ñ…Ð¾Ð´Ð° Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ URL.
func (d *Downloader) Download(startURL string) error {
	return d.downloadRecursive(startURL, 0)
}

// downloadRecursive â€” Ñ€ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸ÐµÐ¼ Ð¿Ð¾ Ð³Ð»ÑƒÐ±Ð¸Ð½Ðµ.
func (d *Downloader) downloadRecursive(rawURL string, depth int) error {
	if depth > d.maxDepth {
		return nil
	}

	u, err := normalizeURL(rawURL)
	if err != nil {
		return fmt.Errorf("failed to normalize URL %s: %w", rawURL, err)
	}

	d.mu.RLock()
	if d.visited[u.String()] {
		d.mu.RUnlock()
		return nil
	}
	d.mu.RUnlock()

	d.mu.Lock()
	d.visited[u.String()] = true
	d.mu.Unlock()

	resp, err := d.fetch(u.String())
	if err != nil {
		return fmt.Errorf("failed to fetch %s: %w", u.String(), err)
	}
	defer resp.Body.Close()

	contentType := resp.Header.Get("Content-Type")
	isHTML := strings.Contains(contentType, "text/html")

	localPath, err := d.getLocalPath(u, isHTML)
	if err != nil {
		return fmt.Errorf("failed to get local path for %s: %w", u.String(), err)
	}

	if err := os.MkdirAll(filepath.Dir(localPath), 0755); err != nil {
		return fmt.Errorf("failed to create dir for %s: %w", localPath, err)
	}

	file, err := os.Create(localPath)
	if err != nil {
		return fmt.Errorf("failed to create file %s: %w", localPath, err)
	}

	_, err = io.Copy(file, resp.Body)
	file.Close()
	if err != nil {
		return fmt.Errorf("failed to save content for %s: %w", localPath, err)
	}

	fmt.Printf("ðŸ“¥ Saved: %s -> %s\n", u.String(), localPath)

	if isHTML {
		err = d.rewriteLinksInHTML(localPath, u)
		if err != nil {
			fmt.Fprintf(os.Stderr, "Failed to rewrite links in %s: %v\n", localPath, err)
		}
	}

	if isHTML && depth < d.maxDepth {
		links, err := extractLinks(localPath, u)
		if err != nil {
			return fmt.Errorf("failed to extract links from %s: %w", localPath, err)
		}

		var wg sync.WaitGroup
		for _, link := range links {
			wg.Add(1)
			go func(l string) {
				defer wg.Done()
				err := d.downloadRecursive(l, depth+1)
				if err != nil {
					fmt.Fprintf(os.Stderr, "Failed to download %s: %v\n", l, err)
				}
			}(link)
		}
		wg.Wait()
	}

	return nil
}

// fetch â€” Ð´ÐµÐ»Ð°ÐµÑ‚ HTTP GET Ð·Ð°Ð¿Ñ€Ð¾Ñ.
func (d *Downloader) fetch(url string) (*http.Response, error) {
	req, err := http.NewRequest("GET", url, nil)
	if err != nil {
		return nil, err
	}
	req.Header.Set("User-Agent", d.userAgent)

	return d.client.Do(req)
}

// getLocalPath â€” Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð°.
func (d *Downloader) getLocalPath(u *url.URL, isHTML bool) (string, error) {
	path := u.Path
	if path == "" || path == "/" {
		path = "/index.html"
	}

	if isHTML && filepath.Ext(path) == "" {
		path += ".html"
	}

	cleanPath := filepath.Clean(path)
	if cleanPath[0] == '/' {
		cleanPath = cleanPath[1:]
	}

	return filepath.Join(d.outputDir, u.Host, cleanPath), nil
}

// normalizeURL â€” Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÑ‚ URL, Ð¿Ñ€Ð¸Ð²Ð¾Ð´Ñ ÐµÐ³Ð¾ Ðº ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ð¼Ñƒ Ð²Ð¸Ð´Ñƒ.
func normalizeURL(raw string) (*url.URL, error) {
	u, err := url.Parse(raw)
	if err != nil {
		return nil, err
	}

	if u.Scheme == "" {
		u.Scheme = "http"
	}

	if u.Host == "" {
		return nil, fmt.Errorf("missing host in URL: %s", raw)
	}

	u.Fragment = ""
	u.RawQuery = ""

	return u, nil
}

// extractLinks â€” Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ ÑÑÑ‹Ð»ÐºÐ¸ Ð¸Ð· HTML-Ñ„Ð°Ð¹Ð»Ð°.
func extractLinks(filePath string, baseURL *url.URL) ([]string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	doc, err := html.Parse(file)
	if err != nil {
		return nil, err
	}

	var links []string
	var f func(*html.Node)
	f = func(n *html.Node) {
		if n.Type == html.ElementNode && (n.Data == "a" || n.Data == "img" || n.Data == "link" || n.Data == "script") {
			for _, attr := range n.Attr {
				if attr.Key == "href" || attr.Key == "src" {
					link := attr.Val
					resolved, err := resolveLink(link, baseURL)
					if err == nil {
						links = append(links, resolved)
					}
				}
			}
		}
		for c := n.FirstChild; c != nil; c = c.NextSibling {
			f(c)
		}
	}
	f(doc)

	unique := make(map[string]bool)
	var result []string
	for _, l := range links {
		if !unique[l] {
			unique[l] = true
			result = append(result, l)
		}
	}

	return result, nil
}

// resolveLink â€” Ñ€Ð°Ð·Ñ€ÐµÑˆÐ°ÐµÑ‚ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ URL.
func resolveLink(link string, baseURL *url.URL) (string, error) {
	if strings.HasPrefix(link, "#") || strings.HasPrefix(link, "mailto:") || strings.HasPrefix(link, "tel:") || strings.HasPrefix(link, "javascript:") {
		return "", nil
	}

	if strings.HasPrefix(link, "http://") || strings.HasPrefix(link, "https://") {
		return link, nil
	}

	u, err := baseURL.Parse(link)
	if err != nil {
		return "", err
	}

	if u.Host != baseURL.Host {
		return "", nil
	}

	return u.String(), nil
}

// rewriteLinksInHTML â€” Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ ÑÑÑ‹Ð»ÐºÐ¸ Ð² HTML-Ñ„Ð°Ð¹Ð»Ðµ Ð½Ð° Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸.
func (d *Downloader) rewriteLinksInHTML(filePath string, baseURL *url.URL) error {
	file, err := os.Open(filePath)
	if err != nil {
		return err
	}
	defer file.Close()

	doc, err := html.Parse(file)
	if err != nil {
		return err
	}

	var f func(*html.Node)
	f = func(n *html.Node) {
		if n.Type == html.ElementNode && (n.Data == "a" || n.Data == "img" || n.Data == "link" || n.Data == "script" || n.Data == "form") {
			for i, attr := range n.Attr {
				key := attr.Key
				val := attr.Val

				if key == "href" || key == "src" || key == "action" {
					resolved, err := resolveLink(val, baseURL)
					if err != nil || resolved == "" {
						continue
					}

					u, _ := url.Parse(resolved)
					localPath, err := d.getLocalPath(u, false) 
					if err != nil {
						continue
					}

					if _, err := os.Stat(localPath); err == nil {
						relPath, err := filepath.Rel(filepath.Dir(filePath), localPath)
						if err != nil {
							continue
						}
						relPath = filepath.ToSlash(relPath)
						n.Attr[i].Val = relPath
					}
				}
			}
		}
		for c := n.FirstChild; c != nil; c = c.NextSibling {
			f(c)
		}
	}
	f(doc)

	outputFile, err := os.Create(filePath)
	if err != nil {
		return err
	}
	defer outputFile.Close()

	return html.Render(outputFile, doc)
}
